ifelse(b,a,"")
?xlab
library(coin)
c("a", "b", "c")
paste0(rep(c("a", "b"),3), c("ratio", "mean", "median"))
paste0(rep(c("a", "b"),each=3), c("ratio", "mean", "median"))
comparePair <- function(data, config, group, ...){
# wilcox test on multigroup
nlevle <- levels(config[, group])
if(length(nlevle) >2 ){
combng <- combn(nlevle, 2)
out <- list()
for(i in 1:ncol(combng)){
subconfig <- config[config[,group] %in% combng[,i], ]
out[i] <- mywilcox_2t(data, subconfig, ...)
}
return(out)
}else{
res <- mywilcox_2t(data, config, ...)
return(out)
}
}
mywilcox_2t <- function(datamatrix, configdata, Time2, ratio="zero",...){
# to sort the data
config <- matchID(configdata, ...)
data <- datamatrix[rownames(config), ,drop=F]
# to analysis
out <- matrix(NA, nrow = ncol(data), ncol = 9)
config <- as.factor(config[, Time2])
nlevels = levels(config)
for(i in 1:ncol(data)){
tmp <- as.numeric(data[,i])
g1 <- tmp[config == nlevels[1]]
g2 <- tmp[config == nlevels[2]]
wilcox_sign <- pvalue(wilcoxsign_test(g1~g2))
effect <- wilcoxonPairedR(x <- tmp, g <- config)
if(ratio=="zero"){
or <- tapply(tmp, config, function(x){sum(x!=0, na.rm=T)/length(x)})
}else{
or <- tapply(tmp, config, function(x){sum(!is.na(x))/length(x)})
}
mean_abun <- tapply(tmp, config, mean, na.rm=T)
median_abun <-  tapply(tmp, config,  median, na.rm=T)
z_score <- statistic(wilcoxsign_test(g1~g2))
out[i, 1:9] <- c(wilcox_sign, or, mean_abun, median_abun, z_score, effect)
}
# out
rownames(out) <- colnames(data)
colnames(out) <- c("sign_p.value",paste0(rep(nlevels,3),
c("_ratio", "_mean", "_median")), "z_score", "effect_size")
out <- as.data.frame(out)
out$p.adjust <- p.adjust(out$sign_p.value, method = "BH")
out$enrich <- ifelse(out$p.adjust<0.05, ifelse(out$z_score>0,
nlevels[1], nlevels[2]), "none")
return(out)
}
??dudi.pco
?pam
??pam
rep(c("a","b"), 2)
paste0(rep(c("a","b"), 2), c("ratio", "mean"))
paste0(rep(c("a","b"), 2), rep(c("ratio", "mean"), 2))
paste0(rep(c("a","b"), 2), rep(c("ratio", "mean"), each =2))
mywilcox_2t <- function(datamatrix, configdata, Time2, ratio="zero",...){
# to sort the data
config <- matchID(configdata, ...)
data <- datamatrix[rownames(config), ,drop=F]
# to analysis
out <- matrix(NA, nrow = ncol(data), ncol = 9)
config <- as.factor(as.character(config[, Time2]))
nlevels = levels(droplevels(config))
for(i in 1:ncol(data)){
tmp <- as.numeric(data[,i])
g1 <- tmp[config == nlevels[1]]
g2 <- tmp[config == nlevels[2]]
wilcox_sign <- pvalue(wilcoxsign_test(g1~g2))
effect <- wilcoxonPairedR(x <- tmp, g <- config)
if(ratio=="zero"){
or <- tapply(tmp, config, function(x){sum(x!=0, na.rm=T)/length(x)})
}else{
or <- tapply(tmp, config, function(x){sum(!is.na(x))/length(x)})
}
mean_abun <- tapply(tmp, config, mean, na.rm=T)
median_abun <-  tapply(tmp, config,  median, na.rm=T)
z_score <- statistic(wilcoxsign_test(g1~g2))
out[i, 1:9] <- c(wilcox_sign, or, mean_abun, median_abun, z_score, effect)
}
# out
rownames(out) <- colnames(data)
colnames(out) <- c("sign_p.value",paste0(rep(nlevels,3),
rep(c("_ratio", "_mean", "_median"), each=2)),
"z_score", "effect_size")
out <- as.data.frame(out)
out$p.adjust <- p.adjust(out$sign_p.value, method = "BH")
out$enrich <- ifelse(out$p.adjust<0.05, ifelse(out$z_score>0,
nlevels[1], nlevels[2]), "none")
return(out)
}
library(caret)
?createFolds
createFolds(c(1:100), k = 10)
createFolds(c(2:100), k = 10)
createFolds(c(2:200), k = 10)
unlist(createFolds(c(2:200), k = 10))
as.vector(unlist(createFolds(c(2:200), k = 10)))
r2Twopartmodelcv <- function(dat , phe, response, cutoff, number=10, cutoffp=0.01, repeatN=100, fold,confounder=NULL){
# match the sample ID
id <- intersect(rownames(dat), rownames(phe))
if(length(id)==0){
stop("can't match the sample id")
}
dat <- dat[id, ]
phe <- phe[id, ]
R2 <- c()
for(m in 1:repeatN){
# print(m)
# cross vlidation
sampNum <- nrow(dat)
foldlist <- createFolds(1:sampNum, k = fold)
risk <- rep(NA, sampNum)
for(n in 1:fold){
discSampindex <- c(1:sampNum)[-foldlist[[n]]]
valiSampindex <- foldlist[[n]]
discDatax <- dat[discSampindex, ]
discPhe <- phe[discSampindex, ]
valiDatax <- dat[valiSampindex, ]
valiPhe <- phe[valiSampindex, response]
# twopart Model to get the effect size
twopartRes <- twopartModel(dat = discDatax, phe = discPhe, response = response,
cutoff = cutoff, number = number)
featurelist <- rownames(twopartRes)[twopartRes[,15] <= cutoffp]
if(length(featurelist)==0){
risk[foldlist[[n]]] <- 0  # if no feature, the rish set zero
next
print(paste0("pvalue cutoff :", cutoffp, " can't get any feature"))
}else{
print(paste0("pvalue cutoff :", cutoffp, " get the significant feature ",
length(featurelist)))
}
# get the additive modele
twopartRes2 <- twopartRes[featurelist, ,drop=F]
valiDatax2  <- valiDatax[, featurelist, drop=F]
risk <- c()
for(i in 1:nrow(valiDatax2)){
riskvalue <- c()
for(j in 1:ncol(valiDatax2)){
beta1 <- twopartRes2[, 4]
beta2 <- twopartRes2[, 8]
b <- ifelse(valiDatax2[i, j] <= cutoff, 0, 1)
q <- ifelse(valiDatax2[i, j] <= cutoff, 0, log10(valiDatax2[i,j]))
riskvalue[j] <- beta1+b+beta2*q  # can't not ecsure why add b
}
risk[foldlist[[n]][i]] <- sum(riskvalue)
}
}
# get the R square
foldindex <- as.vector(unlist(foldlist))
if(!is.null(confounder)){
# risk
tmp <- phe[foldindex, c(response, confounder)]
tmp$risk <- risk
formula <- as.formula(paste0(response, "~."))
lmmode <- summary(lm(formula, data = tmp))
# no risk
tmp2 <- tmp[,-ncol(tmp)]
formula2 <- as.formula(paste0(response, "~."))
lmmode2 <- summary(lm(formula2, data = tmp2))
#　from the rsq.partial in the rsq package
R2[m] <- 1-((1-lmmode$r.squared)/(1-lmmode2$r.squared))*(lmmode2$df[2]/lmmode$df[2])
#R2[m] <- lmmode$adj.r.squared-lmmode2$adj.r.squared
}else{
y <- phe[foldindex, response]
print(y)
print(risk)
lmmode <- summary(lm(y~risk))
R2[m] <- lmmode$r.squared
}
}
return(R2)
}
createFolds(c(1:100), k = 10) -> foldlist
foldlist[[1]]
foldlist[[2]]
foldlist[[3]]
?aes_string
library(ggplot)
install.packages("ggplot2")
a <- "f->f"
a
`a`
``a``
tmp <- data.frame("f->f"=c(1:3))
tmp
tmp <- data.frame("f:f"=c(1:3))
tmp
tmp <- data.frame("3f"=c(1:3))
tmp
install.packages("Rd2roxygen")
library(Rtools)
library(Rtools)
install.packages("Rtools")
install.packages("clusterSim")
install.packages("ggpubr")
install.packages("igraph")
install.packages("glmnet")
install.packages("metfor")
install.packages("metafor")
install.packages("metafor")
install.packages("metafor")
library(rmeta)
library(reshape)
library(pheatmap)
library(glmnet)
# generate the result
out <- data.frame(True = 1, Predict = 1, type1 = "", type2 = "")
out2 <- data.frame(Type = "", Score = 1, type1 = "", type2 = "")
Rresult <- matrix(NA, nrow=length(responsename), ncol=length(datalist))
colnames(Rresult) <-  dataname
rownames(Rresult) <- responsename
feature_plot <- out2[-1, ]
recast(feature_plot, Type+type2~type1) -> qdat
annotation_row <- as.data.frame(qdat[, "type2", drop = F])
rownames(annotation_row) <- paste0("test", 1:nrow(annotation_row))
qdat2 <- qdat[, 3:10]
rownames(qdat2) <- rownames(annotation_row)
qdat2[is.na(qdat2)] <- 0
qdat2[qdat2<0] <- -1
qdat2[qdat2>0] <- 1
# remove the only once
index <- apply(abs(qdat2), 1, function(x){sum(x)>=2})
annotation_row <- annotation_row[index,, drop=F]
qdat3 <- as.data.frame(qdat2[index, ])
head(feature_plot)
head(qdat)
head(qdat2)
qdat3
?recast
recast
?cv.glmnet
?createFolds
library(caret)
?createFolds
createFolds(c(1:100),5)
createFolds(c(1:100),5)
createFolds(c(100:200),5)
?cv.glmnet
set.seed(1010)
n = 1000
p = 100
nzc = trunc(p/10)
x = matrix(rnorm(n * p), n, p)
beta = rnorm(nzc)
fx = x[, seq(nzc)] %*% beta
eps = rnorm(n) * 5
y = drop(fx + eps)
px = exp(fx)
px = px/(1 + px)
ly = rbinom(n = length(px), prob = px, size = 1)
set.seed(1011)
cvob1 = cv.glmnet(x, y)
set.seed(NULL)
cvob1 = cv.glmnet(x, y)
cvob1$lambda.1se
?plot
kwmeta <- function(pr, config){
# set the alpha
alpha <- 0.05  # 0.05
# match names of files
inter <- intersect(rownames(config), rownames(pr))
pr <- t(pr[inter, ])
config <-config[inter,,drop=F]
sum_name <- sum(ifelse(rownames(config)==colnames(pr),1,0))
if(sum_name==nrow(config)){print ("All sample matched")}
print(paste0("the sample number is ",length(inter)))
num <- nrow(pr)
fr <- as.factor(config[, 1])
group <- levels(fr)
print(group)
#output
len <- length(group)
num2 <- len*len/2+3.5*len + 2
out <- matrix(NA, num, num2)
ktp <- apply(pr, 1, function(x){kruskal.test(x ~ fr)$p.value})
#post hoc dunn test
library(PMCMR)
for (i in 1:num) {
pr1 <- as.numeric(pr[i,])
index <- is.na(pr1)
pr1 <- pr1[!index]
fr1 <- fr[!index]
rk  <- rank(pr1)
res <- c(ktp[i], tapply(pr1, fr1, median),tapply(pr1,fr1,mean), tapply(pr1>0, fr1,mean))
dtp <- posthoc.kruskal.dunn.test(pr1, fr1, p.adjust.method = "BH")$p.value
dtp <- cbind(dtp, rep(NA, len - 1))
dtp <- rbind(rep(NA, len), dtp)
dtp[upper.tri(dtp)] <- t(dtp)[upper.tri(dtp)]
rownames(dtp)[1] <- colnames(dtp)[1]
colnames(dtp)[len] <- rownames(dtp)[len]
mean_rank <- tapply(rank(pr1),fr1,mean)
res <- c(res,dtp[lower.tri(dtp)], mean_rank)
#
conclude <- rep(0,2*len-1)
or <- order(mean_rank)
conclude[2*(1:len)-1] <- group[or]
op <- rep(1,len-1)
for(j in 1:(len-1)){op[j] <- dtp[or[j],or[j+1]]}
symbol <- rep("=",len-1)
symbol[!is.na(op) & op <= alpha] <- "<"
symbol[is.na(op) | op == 1] <- "<=>"
for(x in 1:(len-1)){
if(symbol[x]=="<"){
p_tmp <- c()
for(y in 1:x){
for(z in (x+1):len){
p_tmp <- c(p_tmp,dtp[or[y],or[z]])
}
}
if(any(p_tmp>0.05)){symbol[x] <- "="}
}
}
conclude[(1:(len - 1)) * 2] <- symbol
res <- c(res, paste(conclude, collapse = " "))
if(length(res)==ncol(out)){out[i, ] <- res}else{print (res)}
}
rownames(out) <- rownames(pr)
cn <- c("kw.p", paste("median", group[1:len], sep = "_"))
cn <- c(cn,paste("mean", group[1:len], sep = "_"))
cn <- c(cn, paste("or", group[1:len], sep = "_"))
cn <- c(cn, paste0("p", "_", group[row(dtp)[lower.tri(dtp)]], "_", group[col(dtp)[lower.tri(dtp)]]))
cn <- c(cn, paste("mean_rank",group[1:len], sep = "_"))
cn <- c(cn, "nearby")
colnames(out) <- cn
return(out)
}
log10c(1:10)
log10(c(1:10))
?loess
loess(dist ~ speed, cars)
predict(loess(dist ~ speed, cars))
cars$dist
predict(loess(dist ~ speed, cars, span = 0.3))
predict(loess(dist ~ speed, cars, span = 0.5))
?cluster
library(cluster)
?hclust
hc <- hclust(dist(USArrests)^2, "cen")
hc
hc$labels
hc$merge
plot(hc)
library(NbClust)
install.packages("NbClust")
library(NbClust)
?NbClust
x<-rbind(matrix(rnorm(100,sd=0.1),ncol=2),
matrix(rnorm(100,mean=1,sd=0.2),ncol=2),
matrix(rnorm(100,mean=5,sd=0.1),ncol=2),
matrix(rnorm(100,mean=7,sd=0.2),ncol=2))
res<-NbClust(x, distance = "euclidean", min.nc=2, max.nc=8,
method = "complete", index = "ch")
x
res
res$Best.nc
res$Best.nc[1]
cuttree(res)
cutree(res)
example(cutree)
ggplot(data = df, mapping = aes(x = var, y = value, group=variable))
+ geom_line() + geom_point()
library(ggplot2)
ggplot(qdat, mapping = aes(x = var, y = value, group=variable))
+ geom_line() + geom_point()
head(qdat)
names(clusplot())
names(clustlable
)
tapply(vector, index, function)
library(devtools)
install_github("jtclaypool/microbiome")
library(Hmisc)
library(devtools)
install_github("jtclaypool/microbiome")
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(pheatmap)
library(ppcor)
library(ggplot2)
setwd("D:/work/Berberine2/Asssy/09.spearman")
source("./figure.R")
phe <- read.csv("../../Result/00.Phenotype/BerBer_phe_filter.csv", header = T, row.names = 1)
phe$age_class2 <- ifelse(phe$age >=54, 1, 0)
speices <- read.table("../../Result/03.profile/Species/Berber.update.species.pro")
bileacid <- read.csv("../../Result/17.metabolism/Bileacid.metabolism.v3.csv",row.names = 1, header = T)
bilegene <- read.table("../../Result/13.bileacid/bileacid.combind.tab", row.names = 1, header = T, sep = "\t")
speices.clean <- speices[, rownames(phe)]
bileacid.clean <- bileacid[rownames(phe), ]
bilegene.clean <- bilegene[, rownames(phe)]
# filter list (manuly)
filter.species <- read.table("../../Result/03.profile/Species/Berber.species.gene.num.perSample.txt", header = T, row.names = 1, sep = "\t")
retain <- names(which(apply(filter.species, 1, function(x){sum(x>=100)/length(x)})>=0.2))
retain <- gsub(" ", "_", retain)
#bileacid.list <- read.table("bileacid.list.txt")
phe.list <- as.character(read.table("phe.list.txt")[,1])
var <- c("Group","HbA1C", "FPG",  "X2hPPG", "TC", "TG", "HOMAIR", "HOMAB", "HDL_C", "LDL_C", "cp0", "ins0", "cp120", "ins120")
# get clean data
species.clean <- speices.clean[retain, ]
phe.clean <- phe[, phe.list]
species.list <- c("Bifidobacterium_breve",
"Bifidobacterium_longum",
"Lactobacillus_casei",
"Lactobacillus_crispatus",
"Lactobacillus_fermentum",
"Lactobacillus_plantarum",
"Lactobacillus_rhamnosus",
"Lactobacillus_salivarius",
"Lactobacillus_gasseri"
)
species.prob <- speices.clean[species.list, ]
species.other <- species.clean[!rownames(species.clean) %in% species.list, ]
dim(species.prob)
dim(species.other)
!(rownames(species.clean) %in% species.list)
species.prob <- speices[species.list, ]
species.other <- species.clean[!(rownames(species.clean) %in% species.list), ]
dim(species.clean)
dim(species.other)
phe$Time
id <- rownames(phe[phe$Group==1 & phe$Time==3, ])
id
id <- rownames(phe[phe$Group==1 & phe$Time==3, ])
species.prob <- speices[species.list, id]
species.other <- species.clean[!(rownames(species.clean) %in% species.list), id]
myspearman
res <- myspearman(t(species.other), species.prob)
View(res)
figure(res)
figure
res <- myspearman(t(species.prob), species.other)
View(res)
figure(res)
figure()
figure
figure2 <- function(x){
xname <- rownames(x)
x <- apply(x, 2, as.numeric)
sp.corr.t <- x
rownames(sp.corr.t) <- xname
index <- 2*c(1:(ncol(sp.corr.t)/2))
dat.cor <- sp.corr.t[,index]
dat.pvalue <- sp.corr.t[,-index]
colnames(dat.cor) <- colnames(dat.pvalue)
pvalue.index <- apply(dat.pvalue, 2, function(x) any(x < 0.01))
pvalue.index2 <- apply(dat.pvalue, 1, function(x) any(x < 0.01))
dat.cor.cle <- dat.cor[pvalue.index2, pvalue.index]
dat.pva.cle <- dat.pvalue[pvalue.index2, pvalue.index]
num<- matrix(NA,nrow = nrow(dat.pva.cle), ncol = ncol(dat.pva.cle))
for(i in 1:ncol(dat.pva.cle)){
num[,i] <- mapply(trans, dat.pva.cle[,i])
}
colt<-c("#4C38CB","#9191C8","#DADAEC","#F0C1C1","#E28383","#D44545","#CD2626")
pheatmap(dat.cor.cle,
treeheight_row=43,
treeheight_col=23,
cellwidth=20,
cellheight=8,
cluster_cols=T,
cluster_rows=T,
fontsize_row=8,
fontsize_col=13,
show_colnames=T,
display_numbers=num,
color =colt,
breaks=seq(-0.6,0.6,0.2),
legend_breaks = c(-0.6,-0.3, 0, 0.3,0.6),
legend_labels = c("-0.6","-0.3","0", "0.3", "0.6"),
number_color = "black")
}
figure2(res)
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(pheatmap)
library(ppcor)
library(ggplot2)
setwd("D:/work/Berberine2/Asssy/09.spearman")
source("./figure.R")
species.clean2 <- phe[phe$Time==1, ]
function (file, header = FALSE, sep = "", quote = "\"'", dec = ".",
numerals = c("allow.loss", "warn.loss", "no.loss"), row.names,
col.names, as.is = !stringsAsFactors, na.strings = "NA",
colClasses = NA, nrows = -1, skip = 0, check.names = TRUE,
fill = !blank.lines.skip, strip.white = FALSE, blank.lines.skip = TRUE,
comment.char = "#", allowEscapes = FALSE, flush = FALSE,
stringsAsFactors = default.stringsAsFactors(), fileEncoding = "",
encoding = "unknown", text, skipNul = FALSE)
}
phe <- read.csv("../../Result/00.Phenotype/BerBer_phe_filter.csv", header = T, row.names = 1)
phe <- read.csv("../../Result/00.Phenotype/BerBer_phe_filter.csv", header = T, row.names = 1)
species.clean2 <- species.clean[rownames(phe[phe$Time==1, ] ), ]
phe <- read.csv("../../Result/00.Phenotype/BerBer_phe_filter.csv", header = T, row.names = 1)
phe$age_class2 <- ifelse(phe$age >=54, 1, 0)
speices <- read.table("../../Result/03.profile/Species/Berber.update.species.pro")
bileacid <- read.csv("../../Result/17.metabolism/Bileacid.metabolism.v3.csv",
row.names = 1, header = T, check.names = F)
speices.clean <- speices[, rownames(phe)]
bileacid.clean <- bileacid[rownames(phe), ]
# filter list (manuly)
filter.species <- read.table("../../Result/03.profile/Species/Berber.species.gene.num.perSample.txt", header = T, row.names = 1, sep = "\t")
bileacid.list <- read.table("bileacid.list.txt")
phe.list <- read.table("phe.list.txt")
kolist <- c("K00059","K00113","K00121","K00208","K00219","K00632","K00645","K00655","K00968","k01073","K01782","K01825","K01825","K01897","K02371","K02372","K05929","K06076","K06445","K07406","K09458","K10804 ","K11262","K11533","K13509","K13623")
kopro <- read.table("../../Result/03.profile/Ko/Berber2.update.ko.pro", header = T, row.names = 1, sep = "\t")
species.clean2 <- species.clean[rownames(phe[phe$Time==1, ] ), ]
